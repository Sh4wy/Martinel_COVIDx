{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" COVIDX_keras_Breastnet_Kfold.ipynb","provenance":[],"authorship_tag":"ABX9TyOMkNwhOkI0o8jbJAfVp9IX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lxIgX8Uw_VYo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597928342678,"user_tz":-120,"elapsed":1718,"user":{"displayName":"Anthonin Martinel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBJB4KmVJV6_nve0Nj0v2SgLC3JJvZj-S5sD5B=s64","userId":"08903790011573102129"}},"outputId":"22b61ae2-dac6-413c-c949-1289fff8c09f"},"source":["import tensorflow as tf\n","print('tf version : ' + tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tf version : 2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tTRTskrq_bYM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597928344485,"user_tz":-120,"elapsed":3460,"user":{"displayName":"Anthonin Martinel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBJB4KmVJV6_nve0Nj0v2SgLC3JJvZj-S5sD5B=s64","userId":"08903790011573102129"}},"outputId":"55856287-fec6-45ef-fd9a-9bacab7316f5"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qVO2VMZA_dOv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597928349057,"user_tz":-120,"elapsed":7841,"user":{"displayName":"Anthonin Martinel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBJB4KmVJV6_nve0Nj0v2SgLC3JJvZj-S5sD5B=s64","userId":"08903790011573102129"}},"outputId":"32c2a5bb-411f-42af-bbbc-53a9c58d4d78"},"source":["# Unzip CovidX-v4 dataset\n","\n","# unzip Dr Arganda-Carreras's file:\n","# !unzip -q '/content/drive/My Drive/Colab Notebooks/Internship/COVID19_DATA/Covid-X-v4.zip'\n","\n","# unzip mine (a copy of Dr Arganda-Carreras's file)\n","!unzip -q '/content/drive/My Drive/Colab Notebooks/Internship/COVIDX_models/Covid-X-v4.zip'\n","\n","print('Done!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["replace data/test_split.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bphy2Dxa06Ej","colab_type":"text"},"source":["# Nouvelle section"]},{"cell_type":"code","metadata":{"id":"XBu_ETHo0kJ4","colab_type":"code","colab":{}},"source":["from keras.models import Sequential, save_model, load_model\n","from keras import regularizers, optimizers, Model\n","\n","from keras.optimizers import Adam, SGD\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from keras.callbacks import *\n","\n","from sklearn.model_selection import StratifiedKFold, KFold\n","import logging\n","\n","logging.getLogger('tensorflow').setLevel(logging.ERROR)\n","\n","\n","class CosineAnnealer:\n","    \n","    def __init__(self, start, end, steps):\n","        self.start = start\n","        self.end = end\n","        self.steps = steps\n","        self.n = 0\n","        \n","    def step(self):\n","        self.n += 1\n","        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n","        return self.end + (self.start - self.end) / 2. * cos\n","\n","\n","class OneCycleScheduler(Callback):\n","    \"\"\"`Callback` that schedules the learning rate on a 1cycle policy as per Leslie Smith's paper(https://arxiv.org/pdf/1803.09820.pdf).\n","    If the model supports a momentum parameter, it will also be adapted by the schedule.\n","    The implementation adopts additional improvements as per the fastai library: https://docs.fast.ai/callbacks.one_cycle.html, where\n","    only two phases are used and the adaptation is done using cosine annealing.\n","    In phase 1 the LR increases from `lr_max / div_factor` to `lr_max` and momentum decreases from `mom_max` to `mom_min`.\n","    In the second phase the LR decreases from `lr_max` to `lr_max / (div_factor * 1e4)` and momemtum from `mom_max` to `mom_min`.\n","    By default the phases are not of equal length, with the phase 1 percentage controlled by the parameter `phase_1_pct`.\n","    \"\"\"\n","\n","    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n","        super(OneCycleScheduler, self).__init__()\n","        lr_min = lr_max / div_factor\n","        final_lr = lr_max / (div_factor * 1e4)\n","        phase_1_steps = steps * phase_1_pct\n","        phase_2_steps = steps - phase_1_steps\n","        \n","        self.phase_1_steps = phase_1_steps\n","        self.phase_2_steps = phase_2_steps\n","        self.phase = 0\n","        self.step = 0\n","        \n","        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n","                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n","        \n","        self.lrs = []\n","        self.moms = []\n","\n","    def on_train_begin(self, logs=None):\n","        self.phase = 0\n","        self.step = 0\n","\n","        self.set_lr(self.lr_schedule().start)\n","        self.set_momentum(self.mom_schedule().start)\n","        \n","    def on_train_batch_begin(self, batch, logs=None):\n","        self.lrs.append(self.get_lr())\n","        self.moms.append(self.get_momentum())\n","\n","    def on_train_batch_end(self, batch, logs=None):\n","        self.step += 1\n","        if self.step >= self.phase_1_steps:\n","            self.phase = 1\n","            \n","        self.set_lr(self.lr_schedule().step())\n","        self.set_momentum(self.mom_schedule().step())\n","        \n","    def get_lr(self):\n","        try:\n","            return tf.keras.backend.get_value(self.model.optimizer.lr)\n","        except AttributeError:\n","            return None\n","        \n","    def get_momentum(self):\n","        try:\n","            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n","        except AttributeError:\n","            return None\n","        \n","    def set_lr(self, lr):\n","        try:\n","            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n","        except AttributeError:\n","            pass # ignore\n","        \n","    def set_momentum(self, mom):\n","        try:\n","            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n","        except AttributeError:\n","            pass # ignore\n","\n","    def lr_schedule(self):\n","        return self.phases[self.phase][0]\n","    \n","    def mom_schedule(self):\n","        return self.phases[self.phase][1]\n","    \n","    def plot(self):\n","        ax = plt.subplot(1, 2, 1)\n","        ax.plot(self.lrs)\n","        ax.set_title('Learning Rate')\n","        ax = plt.subplot(1, 2, 2)\n","        ax.plot(self.moms)\n","        ax.set_title('Momentum')\n","\n","\n","class LRFinder(Callback):\n","    \"\"\"`Callback` that exponentially adjusts the learning rate after each training batch between `start_lr` and\n","    `end_lr` for a maximum number of batches: `max_step`. The loss and learning rate are recorded at each step allowing\n","    visually finding a good learning rate as per https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html via\n","    the `plot` method.\n","    \"\"\"\n","\n","    def __init__(self, start_lr: float = 1e-7, end_lr: float = 10, max_steps: int = 1000, smoothing=0.9):\n","        super(LRFinder, self).__init__()\n","        self.start_lr, self.end_lr = start_lr, end_lr\n","        self.max_steps = max_steps\n","        self.smoothing = smoothing\n","        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n","        self.lrs, self.losses = [], []\n","\n","    def on_train_begin(self, logs=None):\n","        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n","        self.lrs, self.losses = [], []\n","\n","    def on_train_batch_begin(self, batch, logs=None):\n","        self.lr = self.exp_annealing(self.step)\n","        tf.keras.backend.set_value(self.model.optimizer.lr, self.lr)\n","\n","    def on_train_batch_end(self, batch, logs=None):\n","        logs = logs or {}\n","        loss = logs.get('loss')\n","        step = self.step\n","        if loss:\n","            self.avg_loss = self.smoothing * self.avg_loss + (1 - self.smoothing) * loss\n","            smooth_loss = self.avg_loss / (1 - self.smoothing ** (self.step + 1))\n","            self.losses.append(smooth_loss)\n","            self.lrs.append(self.lr)\n","\n","            if step == 0 or loss < self.best_loss:\n","                self.best_loss = loss\n","\n","            if smooth_loss > 4 * self.best_loss or tf.math.is_nan(smooth_loss):\n","                self.model.stop_training = True\n","\n","        if step == self.max_steps:\n","            self.model.stop_training = True\n","\n","        self.step += 1\n","\n","    def exp_annealing(self, step):\n","        return self.start_lr * (self.end_lr / self.start_lr) ** (step * 1. / self.max_steps)\n","\n","    def plot(self):\n","        fig, ax = plt.subplots(1, 1)\n","        ax.set_ylabel('Loss')\n","        ax.set_xlabel('Learning Rate (log scale)')\n","        ax.set_xscale('log')\n","        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n","        ax.plot(self.lrs, self.losses)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZISt0cnf0pSg","colab_type":"code","colab":{}},"source":["# copied from https://github.com/kobiso/CBAM-keras/blob/master/models/attention_module.py\n","# used for Breastnet model : https://github.com/Goodsea/BreastNet/blob/master/40X/BreastNet_40X.ipynb adapted for keras\n","\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.models import load_model, Model\n","\n","from keras import backend as K\n","SHAPE = (224, 224, 3)\n","from keras.layers import Input\n","\n","def cbam_block(cbam_feature, ratio=8):\n","    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n","    As described in https://arxiv.org/abs/1807.06521.\n","    \"\"\"\n","    \n","    cbam_feature = channel_attention(cbam_feature, ratio)\n","    cbam_feature = spatial_attention(cbam_feature)\n","    return cbam_feature\n","\n","def channel_attention(input_feature, ratio=8):\n","    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","    channel = input_feature._shape[channel_axis] #change _keras_shape into _shape\n","    \n","    shared_layer_one = Dense(channel//ratio,\n","                             activation='relu',\n","                             kernel_initializer='he_normal',\n","                             use_bias=True,\n","                             bias_initializer='zeros')\n","    shared_layer_two = Dense(channel,\n","                             kernel_initializer='he_normal',\n","                             use_bias=True,\n","                             bias_initializer='zeros')\n","    \n","    avg_pool = GlobalAveragePooling2D()(input_feature)    \n","    avg_pool = Reshape((1,1,channel))(avg_pool)\n","    assert avg_pool._shape[1:] == (1,1,channel) #_keras\n","    avg_pool = shared_layer_one(avg_pool)\n","    assert avg_pool._shape[1:] == (1,1,channel//ratio) #_keras\n","    avg_pool = shared_layer_two(avg_pool)\n","    assert avg_pool._shape[1:] == (1,1,channel) #_keras\n","    \n","    max_pool = GlobalMaxPooling2D()(input_feature)\n","    max_pool = Reshape((1,1,channel))(max_pool)\n","    assert max_pool._shape[1:] == (1,1,channel) #_keras\n","    max_pool = shared_layer_one(max_pool)\n","    assert max_pool._shape[1:] == (1,1,channel//ratio) #_keras\n","    max_pool = shared_layer_two(max_pool)\n","    assert max_pool._shape[1:] == (1,1,channel) #_keras\n","    \n","    cbam_feature = Add()([avg_pool,max_pool])\n","    cbam_feature = Activation('sigmoid')(cbam_feature)\n","\n","    if K.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n","    \n","    return multiply([input_feature, cbam_feature])\n","\n","def spatial_attention(input_feature):\n","    kernel_size = 7\n","    \n","    if K.image_data_format() == \"channels_first\":\n","        channel = input_feature._shape[1] #_keras\n","        cbam_feature = Permute((2,3,1))(input_feature)\n","    else:\n","        channel = input_feature._shape[-1] #_keras_\n","        cbam_feature = input_feature\n","    \n","    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n","    assert avg_pool._shape[-1] == 1 #_keras\n","    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n","    assert max_pool._shape[-1] == 1 #_keras\n","    concat = Concatenate(axis=3)([avg_pool, max_pool])\n","    assert concat._shape[-1] == 2 #_keras\n","    cbam_feature = Conv2D(filters = 1,\n","                    kernel_size=kernel_size,\n","                    strides=1,\n","                    padding='same',\n","                    activation='sigmoid',\n","                    kernel_initializer='he_normal',\n","                    use_bias=False)(concat)\t\n","    assert cbam_feature._shape[-1] == 1 #_keras\n","    \n","    if K.image_data_format() == \"channels_first\":\n","        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n","        \n","    return multiply([input_feature, cbam_feature])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1GkVzdx0siP","colab_type":"code","colab":{}},"source":["\n","# credits: https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n","\n","def recall(y_true, y_pred):\n","    \"\"\"\n","    Recall metric.\n","    \n","    Only computes a batch-wise average of recall.\n","    \n","    Computes the recall, a metric for multi-label classification of\n","    how many relevant items are selected.\n","    \"\"\"\n","    \n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision(y_true, y_pred):\n","    \"\"\"Precision metric.\n","    \n","    Only computes a batch-wise average of precision.\n","    \n","    Computes the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\n","    \"\"\"\n","    \n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1(y_true, y_pred):\n","    precisionx = precision(y_true, y_pred)\n","    recallx = recall(y_true, y_pred)\n","    return 2*((precisionx*recallx)/(precisionx+recallx+K.epsilon()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9clbxoo0tBv","colab_type":"code","colab":{}},"source":["# copied from https://gist.github.com/mjdietzx/5319e42637ed7ef095d430cb5c5e8c64\n","def residual_block(y, nb_channels, _strides=(1, 1), _project_shortcut=False):\n","    shortcut = y\n","\n","    # down-sampling is performed with a stride of 2\n","    y = Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n","    y = BatchNormalization()(y)\n","    y = LeakyReLU()(y)\n","\n","    y = Conv2D(nb_channels, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n","    y = BatchNormalization()(y)\n","\n","    # identity shortcuts used directly when the input and output are of the same dimensions\n","    if _project_shortcut or _strides != (1, 1):\n","        # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n","        # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n","        shortcut = Conv2D(nb_channels, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n","        shortcut = BatchNormalization()(shortcut)\n","\n","    y = add([shortcut, y])\n","    y = LeakyReLU()(y)\n","\n","    return y\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zoI55DqC0vrT","colab_type":"code","colab":{}},"source":["# copied from https://github.com/Goodsea/BreastNet/blob/master/40X/BreastNet_40X.ipynb, \"create_model()\"\n","\n","# We adapt this model by adding some dropout layers to counter overfitting\n","def Breastnet_modified_model():\n","    \n","    dropRate = 0.3\n","    \n","    init = Input(SHAPE)\n","    x = Conv2D(32, (3, 3), activation=None, padding='same')(init) \n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(dropRate)(x) # adding dropout\n","    x = Conv2D(32, (3, 3), activation=None, padding='same')(x) \n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(dropRate)(x) # adding dropout\n","    x1 = MaxPooling2D((2,2))(x)\n","    \n","    x = Conv2D(64, (3, 3), activation=None, padding='same')(x1)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(dropRate)(x) # adding dropout\n","    x = cbam_block(x)\n","    x = residual_block(x, 64)\n","    x2 = MaxPooling2D((2,2))(x)\n","    \n","    x = Conv2D(128, (3, 3), activation=None, padding='same')(x2)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(dropRate)(x) # adding dropout\n","    x = cbam_block(x)\n","    x = residual_block(x, 128)\n","    x3 = MaxPooling2D((2,2))(x)\n","    \n","    ginp1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(x1)\n","    ginp2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(x2)\n","    ginp3 = UpSampling2D(size=(8, 8), interpolation='bilinear')(x3)\n","    \n","    hypercolumn = Concatenate()([ginp1, ginp2, ginp3]) \n","    gap = GlobalAveragePooling2D()(hypercolumn)\n","\n","    x = Dense(256, activation=None)(gap)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Dropout(dropRate)(x) # this one was already in the original model\n","    \n","    x = Dense(256, activation=None)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","\n","    y = Dense(3, activation='softmax')(x) # modified it for 3 classes \n","   \n","    model = Model(init, y)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yim_N8mL6mku","colab_type":"code","colab":{}},"source":["def create_model():\n","  # CLR parameters\n","    lr = 5e-3\n","    epochs = 5\n","\n","    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n","    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n","\n","    steps = STEP_SIZE_TRAIN * epochs\n","\n","    lr_schedule = OneCycleScheduler(lr, steps)\n","\n","    base_model = Breastnet_modified_model()\n","\n","    optimizer = tf.keras.optimizers.Adam(lr=lr)\n","\n","    # optimizer = tf.keras.optimizers.Adam(amsgrad=True)\n","    base_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= [precision, recall, f1, 'accuracy']) #, weighted_metrics = class_weights)\n","\n","    # base_model.summary()\n","    return base_model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zbyhHnf201Kx","colab_type":"text"},"source":["# data"]},{"cell_type":"code","metadata":{"id":"nNgvhbuF_ebL","colab_type":"code","colab":{}},"source":["import pathlib\n","path = pathlib.Path( '/content/data' )\n","\n","# Parameters\n","\n","# Model path\n","mod_path = '/content/drive/My Drive/Colab Notebooks/Internship/proto1'\n","\n","k_folds = 4\n","# batch size\n","bs = 64\n","\n","import pandas as pd\n","import numpy as np\n","import keras\n","from keras_preprocessing.image import ImageDataGenerator\n","import io\n","\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","# Paths\n","path_train = pathlib.Path('/content/data/train/')\n","path_test = pathlib.Path('/content/data/test/')\n","\n","\n","# initialize the data and labels\n","data = []\n","labels = []\n","\n","traindf= pd.read_csv(path/\"train_split.txt\", dtype=str, sep=' ', header=None, names=['Image','Name','Class','Origin']) #.drop('Origin',axis=1).drop('Image',axis=1)\n","testdf=pd.read_csv(path/\"test_split.txt\", dtype=str, sep=' ', header=None, names=['Image','Name','Class', 'Origin']) #.drop('Origin',axis=1).drop('Image',axis=1)\n","\n","traindf = traindf[['Name', 'Class']]\n","testdf = testdf[['Name','Class']]\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUpYhjy2wbBH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597930925902,"user_tz":-120,"elapsed":2584623,"user":{"displayName":"Anthonin Martinel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBJB4KmVJV6_nve0Nj0v2SgLC3JJvZj-S5sD5B=s64","userId":"08903790011573102129"}},"outputId":"b59b3ff4-ee0a-449a-8af5-e899c6cfcfac"},"source":["# adapted from https://www.kaggle.com/janged/3rd-ml-month-xception-stratifiedkfold-ensemble\n","\n","from collections import Counter\n","\n","skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=2019)\n","\n","# datagen = ImageDataGenerator(rescale=1./255,\n","#                                 rotation_range=30,\n","# \t                              zoom_range=0.15,\n","# \t                              width_shift_range=0.2,\n","# \t                              height_shift_range=0.2,\n","# \t                              shear_range=0.15,\n","# \t                              horizontal_flip=True,\n","# \t                              fill_mode=\"nearest\")\n","\n","datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","size = 224 # Size of the images\n","\n","\n","model_breastnet_names = []\n","j = 1\n","for (train_index, valid_index) in skf.split(\n","    traindf['Name'], \n","    traindf['Class']):\n","\n","    traindfb = traindf.iloc[train_index, :].reset_index()\n","    validdfb = traindf.iloc[valid_index, :].reset_index()\n","\n","    print(\"============================================\")\n","    print(\"====== K Fold Validation step => %d/%d =======\" % (j,k_folds))\n","    print(\"============================================\")\n","    \n","\n","    train_generator=datagen.flow_from_dataframe(\n","      dataframe=traindfb,\n","      directory=path_train,\n","      x_col='Name',\n","      y_col='Class',\n","      batch_size=bs,\n","      seed=2019,\n","      shuffle=True,\n","      class_mode=\"categorical\",\n","      target_size=(size,size))\n","\n","    valid_generator=datagen.flow_from_dataframe(\n","      dataframe=validdfb,\n","      directory=path_train,\n","      x_col='Name',\n","      y_col='Class',\n","      batch_size=bs,\n","      seed=2019,\n","      shuffle=True,\n","      class_mode=\"categorical\",\n","      target_size=(size,size))\n","    \n","\n","    # compute class weight:\n","    labels_count = Counter()\n","\n","    for word in traindf['Class']:\n","      labels_count[word] += 1\n","\n","    total_count = sum(labels_count.values())\n","    class_weights = {cls: total_count / count for cls, count in labels_count.items()}\n","\n","    class_weights[train_generator.class_indices['COVID-19']] = class_weights.pop('COVID-19')\n","    class_weights[train_generator.class_indices['normal']] = class_weights.pop('normal')\n","    class_weights[train_generator.class_indices['pneumonia']] = class_weights.pop('pneumonia')\n","\n","\n","    model_name = str(j) + '_breastnet.hdf5'\n","    model_breastnet_names.append(model_name)\n","    \n","    base_model = create_model()\n","\n","    checkpoint_callback = ModelCheckpoint(\n","      filepath=model_name,\n","      monitor='val_loss', \n","      mode='min', \n","      verbose=1, \n","      save_best_only=True, \n","      save_weights_only=False)\n","\n","\n","    History = base_model.fit_generator(generator=train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=valid_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    class_weight=class_weights, # We change the weights\n","                    epochs=epochs,\n","                    callbacks=[checkpoint_callback, lr_schedule],\n","                    workers=4,\n","                    verbose = 2)\n","        \n","    j+=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["============================================\n","====== K Fold Validation step => 1/4 =======\n","============================================\n","Found 10419 validated image filenames belonging to 3 classes.\n","Found 3473 validated image filenames belonging to 3 classes.\n","Epoch 1/5\n","\n","Epoch 00001: val_loss improved from inf to 1.62746, saving model to 1_breastnet.hdf5\n","162/162 - 130s - loss: 3.7460 - precision: 0.3493 - recall: 0.2351 - f1: 0.2805 - accuracy: 0.3360 - val_loss: 1.6275 - val_precision: 0.0336 - val_recall: 0.0336 - val_f1: 0.0336 - val_accuracy: 0.0336\n","Epoch 2/5\n","\n","Epoch 00002: val_loss did not improve from 1.62746\n","162/162 - 127s - loss: 2.5171 - precision: 0.6277 - recall: 0.4858 - f1: 0.5467 - accuracy: 0.5862 - val_loss: 2.0832 - val_precision: 0.0333 - val_recall: 0.0333 - val_f1: 0.0333 - val_accuracy: 0.0333\n","Epoch 3/5\n","\n","Epoch 00003: val_loss did not improve from 1.62746\n","162/162 - 127s - loss: 2.2808 - precision: 0.7020 - recall: 0.5813 - f1: 0.6355 - accuracy: 0.6539 - val_loss: 2.3511 - val_precision: 0.0342 - val_recall: 0.0341 - val_f1: 0.0342 - val_accuracy: 0.0341\n","Epoch 4/5\n","\n","Epoch 00004: val_loss did not improve from 1.62746\n","162/162 - 126s - loss: 2.0894 - precision: 0.7334 - recall: 0.6353 - f1: 0.6805 - accuracy: 0.6963 - val_loss: 2.5962 - val_precision: 0.0738 - val_recall: 0.0718 - val_f1: 0.0728 - val_accuracy: 0.0784\n","Epoch 5/5\n","\n","Epoch 00005: val_loss did not improve from 1.62746\n","162/162 - 125s - loss: 1.9520 - precision: 0.7592 - recall: 0.6600 - f1: 0.7057 - accuracy: 0.7215 - val_loss: 3.5403 - val_precision: 0.0673 - val_recall: 0.0666 - val_f1: 0.0669 - val_accuracy: 0.0706\n","============================================\n","====== K Fold Validation step => 2/4 =======\n","============================================\n","Found 10419 validated image filenames belonging to 3 classes.\n","Found 3473 validated image filenames belonging to 3 classes.\n","Epoch 1/5\n","\n","Epoch 00001: val_loss improved from inf to 1.32900, saving model to 2_breastnet.hdf5\n","162/162 - 128s - loss: 3.4997 - precision: 0.4407 - recall: 0.2507 - f1: 0.3184 - accuracy: 0.4144 - val_loss: 1.3290 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - val_accuracy: 0.3681\n","Epoch 2/5\n","\n","Epoch 00002: val_loss did not improve from 1.32900\n","162/162 - 124s - loss: 2.5814 - precision: 0.6488 - recall: 0.4858 - f1: 0.5541 - accuracy: 0.5995 - val_loss: 5.4606 - val_precision: 0.0339 - val_recall: 0.0339 - val_f1: 0.0339 - val_accuracy: 0.0339\n","Epoch 3/5\n","\n","Epoch 00003: val_loss did not improve from 1.32900\n","162/162 - 124s - loss: 2.2886 - precision: 0.7094 - recall: 0.5861 - f1: 0.6413 - accuracy: 0.6625 - val_loss: 6.9892 - val_precision: 0.0341 - val_recall: 0.0341 - val_f1: 0.0341 - val_accuracy: 0.0341\n","Epoch 4/5\n","\n","Epoch 00004: val_loss did not improve from 1.32900\n","162/162 - 124s - loss: 2.1021 - precision: 0.7347 - recall: 0.6241 - f1: 0.6745 - accuracy: 0.6885 - val_loss: 7.3348 - val_precision: 0.0388 - val_recall: 0.0388 - val_f1: 0.0388 - val_accuracy: 0.0388\n","Epoch 5/5\n","\n","Epoch 00005: val_loss did not improve from 1.32900\n","162/162 - 124s - loss: 1.9946 - precision: 0.7571 - recall: 0.6517 - f1: 0.7001 - accuracy: 0.7121 - val_loss: 7.2712 - val_precision: 0.0486 - val_recall: 0.0486 - val_f1: 0.0486 - val_accuracy: 0.0486\n","============================================\n","====== K Fold Validation step => 3/4 =======\n","============================================\n","Found 10419 validated image filenames belonging to 3 classes.\n","Found 3473 validated image filenames belonging to 3 classes.\n","Epoch 1/5\n","\n","Epoch 00001: val_loss improved from inf to 2.21802, saving model to 3_breastnet.hdf5\n","162/162 - 126s - loss: 3.2777 - precision: 0.4285 - recall: 0.2618 - f1: 0.3238 - accuracy: 0.4072 - val_loss: 2.2180 - val_precision: 0.3924 - val_recall: 0.3924 - val_f1: 0.3924 - val_accuracy: 0.3924\n","Epoch 2/5\n","\n","Epoch 00002: val_loss did not improve from 2.21802\n","162/162 - 124s - loss: 2.3896 - precision: 0.6742 - recall: 0.5310 - f1: 0.5930 - accuracy: 0.6287 - val_loss: 2.5377 - val_precision: 0.3924 - val_recall: 0.3924 - val_f1: 0.3924 - val_accuracy: 0.3924\n","Epoch 3/5\n","\n","Epoch 00003: val_loss did not improve from 2.21802\n","162/162 - 125s - loss: 2.1044 - precision: 0.7342 - recall: 0.6265 - f1: 0.6756 - accuracy: 0.6930 - val_loss: 5.2218 - val_precision: 0.0359 - val_recall: 0.0359 - val_f1: 0.0359 - val_accuracy: 0.0359\n","Epoch 4/5\n","\n","Epoch 00004: val_loss did not improve from 2.21802\n","162/162 - 125s - loss: 1.9234 - precision: 0.7589 - recall: 0.6592 - f1: 0.7052 - accuracy: 0.7217 - val_loss: 5.3750 - val_precision: 0.0901 - val_recall: 0.0891 - val_f1: 0.0896 - val_accuracy: 0.0923\n","Epoch 5/5\n","\n","Epoch 00005: val_loss did not improve from 2.21802\n","162/162 - 125s - loss: 1.8051 - precision: 0.7733 - recall: 0.6759 - f1: 0.7209 - accuracy: 0.7340 - val_loss: 7.2674 - val_precision: 0.0581 - val_recall: 0.0579 - val_f1: 0.0580 - val_accuracy: 0.0596\n","============================================\n","====== K Fold Validation step => 4/4 =======\n","============================================\n","Found 10419 validated image filenames belonging to 3 classes.\n","Found 3473 validated image filenames belonging to 3 classes.\n","Epoch 1/5\n","\n","Epoch 00001: val_loss improved from inf to 2.07737, saving model to 4_breastnet.hdf5\n","162/162 - 126s - loss: 3.5217 - precision: 0.5437 - recall: 0.4104 - f1: 0.4670 - accuracy: 0.5188 - val_loss: 2.0774 - val_precision: 0.0336 - val_recall: 0.0336 - val_f1: 0.0336 - val_accuracy: 0.0336\n","Epoch 2/5\n","\n","Epoch 00002: val_loss did not improve from 2.07737\n","162/162 - 125s - loss: 2.5786 - precision: 0.6507 - recall: 0.5196 - f1: 0.5771 - accuracy: 0.6126 - val_loss: 4.1563 - val_precision: 0.0333 - val_recall: 0.0333 - val_f1: 0.0333 - val_accuracy: 0.0333\n","Epoch 3/5\n","\n","Epoch 00003: val_loss did not improve from 2.07737\n","162/162 - 124s - loss: 2.2936 - precision: 0.6869 - recall: 0.5731 - f1: 0.6243 - accuracy: 0.6515 - val_loss: 5.0578 - val_precision: 0.0336 - val_recall: 0.0336 - val_f1: 0.0336 - val_accuracy: 0.0336\n","Epoch 4/5\n","\n","Epoch 00004: val_loss did not improve from 2.07737\n","162/162 - 124s - loss: 2.1357 - precision: 0.7168 - recall: 0.6129 - f1: 0.6603 - accuracy: 0.6771 - val_loss: 5.6330 - val_precision: 0.0469 - val_recall: 0.0469 - val_f1: 0.0469 - val_accuracy: 0.0475\n","Epoch 5/5\n","\n","Epoch 00005: val_loss did not improve from 2.07737\n","162/162 - 124s - loss: 2.0523 - precision: 0.7251 - recall: 0.6217 - f1: 0.6690 - accuracy: 0.6897 - val_loss: 5.3380 - val_precision: 0.0699 - val_recall: 0.0697 - val_f1: 0.0698 - val_accuracy: 0.0706\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sHW788TP3IGp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"status":"ok","timestamp":1597931012511,"user_tz":-120,"elapsed":2671220,"user":{"displayName":"Anthonin Martinel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBJB4KmVJV6_nve0Nj0v2SgLC3JJvZj-S5sD5B=s64","userId":"08903790011573102129"}},"outputId":"92ff34e5-3226-4204-b9d5-837e5b04b2d4"},"source":["test_datagen=ImageDataGenerator(rescale=1./255)\n","\n","test_generator=test_datagen.flow_from_dataframe(\n","  dataframe=testdf,\n","  directory=path_test,\n","  x_col='Name',\n","  y_col=None,\n","  batch_size=bs,\n","  shuffle=False, #DO NOT SHUFFLE, otherwise you won't be able to calculate monitors afterward \n","  class_mode=None,\n","  target_size=(size,size))\n","\n","\n","breastnet_prediction = []\n","for i, name in enumerate(model_breastnet_names):\n","\n","    model_bn = create_model()\n","\n","    model_bn.load_weights(name)\n","    test_generator.reset()\n","    pred = model_bn.predict_generator(\n","        generator=test_generator,\n","        # steps = test_generator.n//test_generator.batch_size,\n","        verbose=1\n","    )\n","    breastnet_prediction.append(pred)\n","\n","y_pred_breastnet = np.mean(breastnet_prediction, axis=0)\n","\n","class_guess=np.argmax(y_pred_breastnet, axis=1)\n","\n","# adapted from COVIDX-Fastai-XResNet18.ipynb\n","# Convert dataframe test labels to list\n","gt = testdf['Class'].tolist()\n","\n","# Convert from label names to class index values (0, 1, 2)\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix\n","labels = ['COVID-19', 'normal', 'pneumonia']\n","le = preprocessing.LabelEncoder()\n","targets = le.fit_transform(labels)\n","test_preds = le.transform( gt )\n","\n","print(\"Size of class_guess : \" + str(np.size(class_guess)))\n","print(\"Size of test_preds : \" + str(np.size(np.asarray( test_preds ))))\n","print(\"class_guess : \" + str(class_guess))\n","print(\"test_preds : \" + str(test_preds))\n","\n","# Calculate accuracy\n","from sklearn.metrics import accuracy_score\n","acc = accuracy_score( class_guess, np.asarray( test_preds ) )\n","print( \"Accuracy = \" + str( acc ) )\n","\n","# Calculate precision per class\n","print(labels)\n","\n","from sklearn.metrics import precision_score\n","prec = precision_score( class_guess, np.asarray( test_preds ), average=None )\n","print( \"Precision (Positive Predictive Value) per class = \" + str( prec ))\n","\n","# Calculate recall per class\n","from sklearn.metrics import recall_score\n","rec = recall_score(class_guess, np.asarray(test_preds), average=None )\n","print( \"Recall (Sensitiviy) per class = \" + str( rec ))\n","\n","\n","print('Confusion Matrix')\n","print(confusion_matrix(np.asarray( test_preds ), class_guess))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1579 validated image filenames.\n","25/25 [==============================] - 17s 662ms/step\n","25/25 [==============================] - 16s 658ms/step\n","25/25 [==============================] - 16s 656ms/step\n","25/25 [==============================] - 16s 653ms/step\n","Size of class_guess : 1579\n","Size of test_preds : 1579\n","class_guess : [0 0 0 ... 0 0 0]\n","test_preds : [2 2 2 ... 2 2 2]\n","Accuracy = 0.06269791006966434\n","['COVID-19', 'normal', 'pneumonia']\n","Precision (Positive Predictive Value) per class = [0.99 0.   0.  ]\n","Recall (Sensitiviy) per class = [0.06277743 0.         0.        ]\n","Confusion Matrix\n","[[ 99   0   1]\n"," [884   0   1]\n"," [594   0   0]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}